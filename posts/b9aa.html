<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>机器学习与数据挖掘 刷题练习(复习版) | AriesfunのBlog</title><meta name="keywords" content="学习记录,机器学习与数据挖掘"><meta name="author" content="Ariesfun"><meta name="copyright" content="Ariesfun"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="机器学习与数据挖掘 刷题练习(复习版)闲言碎语： 本文是自己在准备数据挖掘结课考试时，自己整理的学习笔记，放在这存个档。 这门课我只是较为浅显的知道了一些理论概念，不过这门课的知识实践需要花费较多的时间和精力，是我本专业必 学的一门核心课，以后我可能还能用上哈~~ 一、单选题及判断 1.数据1.不属于数据的属性类型的是，相异 数据的属性类型包括标称、序数、区间和比率等四种 2.原始数据存在的几个问">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习与数据挖掘 刷题练习(复习版)">
<meta property="og:url" content="https://ariesfun.gitee.io/posts/b9aa.html">
<meta property="og:site_name" content="AriesfunのBlog">
<meta property="og:description" content="机器学习与数据挖掘 刷题练习(复习版)闲言碎语： 本文是自己在准备数据挖掘结课考试时，自己整理的学习笔记，放在这存个档。 这门课我只是较为浅显的知道了一些理论概念，不过这门课的知识实践需要花费较多的时间和精力，是我本专业必 学的一门核心课，以后我可能还能用上哈~~ 一、单选题及判断 1.数据1.不属于数据的属性类型的是，相异 数据的属性类型包括标称、序数、区间和比率等四种 2.原始数据存在的几个问">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/202306040216162.jpg">
<meta property="article:published_time" content="2023-06-03T18:17:05.594Z">
<meta property="article:modified_time" content="2023-06-04T03:20:07.551Z">
<meta property="article:author" content="Ariesfun">
<meta property="article:tag" content="学习记录">
<meta property="article:tag" content="机器学习与数据挖掘">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/202306040216162.jpg"><link rel="shortcut icon" href="/img/logo_22.png"><link rel="canonical" href="https://ariesfun.gitee.io/posts/b9aa"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: {"limitDay":500,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: Ariesfun","link":"链接: ","source":"来源: AriesfunのBlog","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'mediumZoom',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '机器学习与数据挖掘 刷题练习(复习版)',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-06-04 11:20:07'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/gradient_background.css"><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="AriesfunのBlog" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-dark.css" type="text/css"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/logo_22.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">48</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">32</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">17</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/friends/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于作者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/202306040216162.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">AriesfunのBlog</a></span><div id="he-plugin-simple"></div><div id="none_space"></div><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/friends/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于作者</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">机器学习与数据挖掘 刷题练习(复习版)</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-06-03T18:17:05.594Z" title="发表于 2023-06-04 02:17:05">2023-06-04</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-06-04T03:20:07.551Z" title="更新于 2023-06-04 11:20:07">2023-06-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">数据挖掘与机器学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">6.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>22分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="机器学习与数据挖掘 刷题练习(复习版)"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="机器学习与数据挖掘-刷题练习-复习版"><a href="#机器学习与数据挖掘-刷题练习-复习版" class="headerlink" title="机器学习与数据挖掘 刷题练习(复习版)"></a>机器学习与数据挖掘 刷题练习(复习版)</h2><p>闲言碎语：</p>
<p>本文是自己在准备数据挖掘结课考试时，自己整理的学习笔记，放在这存个档。</p>
<p>这门课我只是较为浅显的知道了一些理论概念，不过这门课的知识实践需要花费较多的时间和精力，是我本专业必</p>
<p>学的一门核心课，以后我可能还能用上哈~~</p>
<h2 id="一、单选题及判断"><a href="#一、单选题及判断" class="headerlink" title="一、单选题及判断"></a>一、单选题及判断</h2><hr>
<h3 id="1-数据"><a href="#1-数据" class="headerlink" title="1.数据"></a><strong>1.数据</strong></h3><p>1.不属于<u>数据的属性类型</u>的是，<strong>相异</strong></p>
<p>数据的属性类型包括<u>标称、序数、区间和比率等四种</u></p>
<p>2.原始数据<u>存在的几个问题</u>不包括，<strong>不重复</strong></p>
<p><strong>数据挖掘(Data Mining)就是从大量的、不完全的、有噪声的、模糊的</strong>、随机的实际应用数据中,提取隐含在其中的、人们事先不知道的、但又是潜在有用的信息和知识的过程</p>
<p><strong>对于数据挖掘中的原始数据，存在的问题有</strong>？ABCD</p>
<p><strong>A. 不一致    B. 重复    C. 不完整    D. 含噪声</strong></p>
<p>3.数据挖掘中使用的数据的原则不包括，<strong>保留唯一性</strong></p>
<p>4.<strong>数据预处理的效果</strong>直接决定了机器学习的结果质量</p>
<p>5.噪声数据的产生原因主要有？ABC</p>
<ul>
<li><strong>A. 数据采集设备有问题</strong></li>
<li><strong>B. 在数据录入过程中发生了人为或计算机错误</strong></li>
<li><strong>C. 数据传输过程中发生错误</strong></li>
</ul>
<p>6.数据挖掘的任务包含（ ABCDE）</p>
<ul>
<li><strong>A. 关联分析</strong></li>
<li><strong>B. 时序模式分析</strong></li>
<li><strong>C. 聚类</strong></li>
<li><strong>D. 分类</strong></li>
<li><strong>E. 偏差检测</strong> </li>
</ul>
<p>7.在数据集成时，来自多个数据源的现实世界实体的表达形式是不一样的，不一定是匹配的，<u>要考虑实体识别问题和属性冗余问题，从而把源数据在最低层上加以转换、提炼和集成。</u> <strong>A. 对</strong></p>
<p>8.给定 n 个数据点，如果其中一半用于训练，另一半用于测试，则训练误差和测试误差之间的差别会<strong>随着 n的增加而减小</strong>。 <strong>A. 对</strong></p>
<p>9.知识发现（KDD）包含<u>数据准备、数据挖掘、结果评价</u>三个阶段。 <strong>对的</strong></p>
<p>10.<u>通过数据规约</u>，可以达到（  ABC ） </p>
<ul>
<li><strong>A. 降低无效、错误数据对建模的影响，提高建模的准确性</strong></li>
<li><strong>B. 少量且具代表性的数据将大幅缩减数据挖掘所需的时间</strong></li>
<li><strong>C. 降低储存数据的成本</strong></li>
</ul>
<p>11.<strong>数据预处理方法</strong>主要有？ABCD</p>
<ul>
<li><strong>A. 数据清洗</strong></li>
<li><strong>B. 数据集成</strong></li>
<li><strong>C. 数据变换</strong></li>
<li><strong>D. 数据归约</strong></li>
</ul>
<p>11.1数据挖掘的<u>数据准备阶段</u>的主要工作包含（ ABCDE）。</p>
<ul>
<li><strong>A. 消除噪声</strong></li>
<li><strong>B. 推导计算缺值数据</strong></li>
<li><strong>C. 消除重复记录</strong></li>
<li><strong>D. 数据转换</strong></li>
<li><strong>E. 消减数据维数或降维</strong></li>
</ul>
<p>13.<strong>特征选择可以？****ABC</strong></p>
<ul>
<li><strong>A. 选择区分能力强的数据</strong></li>
<li><strong>B. 降低模型分析的时间复杂度</strong></li>
<li><strong>C. 减少无效特征</strong></li>
</ul>
<p>14.<strong>信息增益度量</strong>偏向具有许多输出的测试，也就是说它<strong>倾向于选择具有大量值的属性</strong>。 <strong>A. 对</strong></p>
<hr>
<h3 id="2-数据仓库"><a href="#2-数据仓库" class="headerlink" title="2.数据仓库"></a><strong>2.数据仓库</strong></h3><p>1.以下各项均是针对数据仓库的不同说法,你<strong>认为正确的有</strong>，ABCD</p>
<ul>
<li><u>B. 数据仓库是一切商业智能系统的基础</u></li>
<li><u>C. 数据仓库是面向业务的,支持联机事务处理(OLTP)</u></li>
<li><u>D. 数据仓库支持决策而非事务处理</u></li>
<li><u>E. 数据仓库的主要目标就是帮助分析,做长期性的战略制定</u></li>
</ul>
<p>2.关于OLAP和OLTP的说法,<strong>下列不正确的是</strong>(   A   ) </p>
<ul>
<li><strong>A.  OLAP事务量大,但事务内容比较简单且重复率高.</strong></li>
<li>B. OLAP的最终数据来源与OLTP不一样.</li>
<li>C. OLTP面对的是决策人员和高层管理人员.</li>
<li>D. OLTP以应用为核心,是应用驱动的.</li>
</ul>
<p>3.<strong>OLAP技术的核心是，多维分析</strong></p>
<p>4<u>.数据仓库是随着时间变化的,下面的描述不正确的是</u>(  C   ) </p>
<ul>
<li><p>A. 数据仓库随时间的变化不断增加新的数据内容;</p>
</li>
<li><p>B. 捕捉到的新数据会覆盖原来的快照;</p>
</li>
<li><p><strong>C. 数据仓库随事件变化不断删去旧的数据内容;</strong></p>
</li>
<li><p>D. 数据仓库中包含大量的综合数据,这些综合数据会随着时间的变化不断地进行重新综合</p>
</li>
</ul>
<hr>
<h3 id="3-机器学习方法"><a href="#3-机器学习方法" class="headerlink" title="3.机器学习方法"></a><strong>3.机器学习方法</strong></h3><p>1.<strong>移动运营商对客户的流失进行预测</strong>,可以使用下面哪种机器学习方法比较合适 ,   <strong>多层前馈网络</strong></p>
<p>2.下列哪些模型可以用来判断特征的重要性？（ <strong>ABDE</strong>   ） </p>
<ul>
<li><strong>A. 随机森林（Random Forest）</strong></li>
<li><strong>B. 线性回归（Linear Regression）</strong></li>
<li>C. 支持向量机（SVM）</li>
<li><strong>D. 方差分析（ANOVA）</strong></li>
<li><strong>E. 逻辑回归（LogisticRegression）</strong></li>
</ul>
<p>​                                            </p>
<p>3.<strong>机器学习</strong>是<u>人工智能里面一个非常重要的<strong>技术</strong></u>，<strong>深度学习</strong>是<u>机器学习里面的一种方法</u>。 <strong>A. 对</strong></p>
<p>4.下列哪些<strong>机器学习算法不需要做归一化处理</strong>(  CE    )</p>
<ul>
<li><strong>C. DecisionTree 决策树</strong></li>
<li><strong>E. Naive Bayes classifier 贝叶斯</strong></li>
</ul>
<p>5.<u>泛化能力是机器学习中衡量学习机性能好坏的一个重要指标</u>，主要是指学习机对预测样本<strong>进行正确预测的能力</strong>。<strong>A. 对</strong></p>
<hr>
<h3 id="4-装袋"><a href="#4-装袋" class="headerlink" title="4.装袋"></a><strong>4.装袋</strong></h3><p>1.<strong>Bagging</strong>的主要特点有，   ABD</p>
<p> <strong>A. 各基础分类器并行生成   B. 各基础分类器权重相同  D. 基于Bootstrap采样生成训练集</strong></p>
<p>2.对<strong>Boosting模型</strong>的描述正确的是，</p>
<p><strong>A.  采用串行训练模式    C.  通过改变训练集进行有针对性的学习</strong></p>
<p>3.<u>装袋法中每个样本被选中概率相同</u>,所以噪声数据的影响下降,<u>容易受过拟合的影响</u>( ) <strong>错误</strong></p>
<hr>
<h3 id="5-决策树"><a href="#5-决策树" class="headerlink" title="5.决策树"></a><strong>5.决策树</strong></h3><p>1.决策树中属性选择的方法有？BCD</p>
<p><strong>B. 信息增益 C. 信息增益率 D. GINI系数</strong></p>
<p>2.下面的决策树中，不能解决回归问题的是？ABC</p>
<p><strong>A. ID3 B. C4.5 C. C5.0</strong></p>
<p>3.0决策树模型<strong>不适合</strong>训练集数据量较大的情况。<strong>错的</strong></p>
<p>3.1<u>决策树不擅长处理非数值型数据</u>。<strong>错的</strong></p>
<p>3.2<u>逻辑回归分析需要对离散值做预处理</u>，决策树则不需要。( ）<strong>A. 对</strong></p>
<p>3.3决策树算法<strong>只能处理二分类</strong>，不能处理多分类。 <strong>错的</strong></p>
<p>4.DecisionTreeClassifier实现了决策树的构建，下列说法正确的有（ <strong>ABCD</strong> ） </p>
<ul>
<li><strong>A. 参数criterion的取值有gini，entropy两种。</strong></li>
<li><strong>B. 参数max_depth限定了决策树的最大深度，对于防止过拟合非常有用。</strong></li>
<li><strong>C. 参数min_samples_leaf 限定了叶子结点包含的最小样本数。</strong></li>
<li><strong>D. gini越小，表示纯度越高。</strong></li>
</ul>
<p>5.<u>有关决策树的分类方法</u>正确的是( B )。</p>
<p><strong>B.决策树可以用于发现多种样本的特征</strong></p>
<p>6.逻辑回归分析需要<strong>对离散值做预处理</strong>，决策树则不需要。( ）    <strong>A. 对</strong></p>
<hr>
<h3 id="6-随机森林"><a href="#6-随机森林" class="headerlink" title="6.随机森林"></a><strong>6.随机森林</strong></h3><p>1.下面哪些<u>超参数的增加可能会造成随机森林数据过拟合</u>？<strong>A. 树的数量  B. 树的深度</strong></p>
<p>2.下列关于**<u>随机森林的描述正确</u>**的是(ABCD)。</p>
<ul>
<li><strong>A.  与袋装法采用相同样本抽取方式</strong></li>
<li><strong>B.  每次从所有属性中随机抽取t个属性来训练分类器</strong></li>
<li><strong>C.  每次从所有样本中选取一定比例的样本来训练分类器</strong></li>
<li><strong>D.  可以使用不同的决策树的组合来构建分类模型</strong></li>
</ul>
<hr>
<h3 id="7-分类"><a href="#7-分类" class="headerlink" title="7.分类"></a><strong>7.分类</strong></h3><p>1.<strong>分类算法有C4.5</strong></p>
<p><strong>常用的分类算法包括</strong>（  ABCD），</p>
<p><strong>A. 决策树 B. 支持向量机 C. 贝叶斯网络 D. 神经网络</strong></p>
<p><u>解决分类问题的方法</u>包括？ <strong>ABCD</strong></p>
<p><strong>A. 决策树    B. 贝叶斯    C. 人工神经网络    D. 支持向量机</strong></p>
<p>2.以下属于<u>分类器评价或比较尺度</u>的有:     </p>
<p>​    <strong>A.预测准确度</strong><br>​    <strong>C.模型描述的简洁度</strong><br>​    <strong>D.计算复杂度</strong></p>
<p>3.哪些<u>不是最近邻分类器的特点</u>，</p>
<p><strong>C.  最近邻分类器基于全局信息进行预测</strong></p>
<p>4.通过<strong>聚集多个分类器的预测</strong>来提高分类准确率的技术称为， <strong>组合(ensemble)</strong></p>
<p>5.**<u>评估分类器预测能力的度量包括</u>**（      ） </p>
<ul>
<li><strong>A. 准确率</strong></li>
<li><strong>B. 灵敏度(又称为召回率)</strong></li>
<li><strong>C. 特效性</strong></li>
<li><strong>D. 精度</strong></li>
<li><strong>E. F1和Fβ</strong></li>
</ul>
<p>6.在评价<strong>不平衡类问题分类的度量方法</strong>有如下几种,( )</p>
<p><strong>A. F1度量</strong><br><strong>B. 召回率(recall)</strong><br><strong>C. 精度(precision)</strong><br><strong>D. 真正率(ture positive rate,TPR)</strong></p>
<p>7.一般来说，回归不用在分类问题上，但是也有特殊情况，<u>比如logistic 回归可以用来解决0/1分类问题。（  ）</u> <strong>A. 对</strong></p>
<p>8.<strong>分类是有监督的学习，聚类是无监督的学习</strong></p>
<p>9.<strong>受试者操作特征曲线</strong>(Receiver Operating Characteristic Curve，<strong>ROC</strong>)是一种反映分类模型敏感性和特异性连续变量的综合，<u>ROC的横坐标，纵坐标分别表示（        ）</u></p>
<p><strong>A. 假正例率（FPR），真正例率（TPR）</strong></p>
<p><strong>E. 假阳率（特异度），真阳率（灵敏度）</strong></p>
<p>10.<strong>组合方法</strong>可以通过学习和组合一系列个体（基）<strong>分类器模型</strong>来提高总体准确率，主要的组合方法有（   ABC  ）。 </p>
<p><strong>A. 装袋    B. 提升    C. 随机森林</strong></p>
<p>11.在谈到分类时，<u>数据元组</u>也称为？ABCD</p>
<ul>
<li><p><strong>A. 样本</strong></p>
</li>
<li><p><strong>B. 实例</strong></p>
</li>
<li><p><strong>C. 数据点</strong></p>
</li>
<li><p><strong>D. 对象</strong></p>
</li>
</ul>
<p>12.<u>数据分类是一个两阶段过程</u>，包括（ ）和分类阶段。<strong>学习阶段</strong></p>
<p>13.<u>分类器的构造与评估需要把标记的数据集划分成训练集和检验集</u>，典型方法包含（   ABCD  ）。 </p>
<ul>
<li><strong>A. 保持</strong></li>
<li><strong>B. 随机抽样</strong></li>
<li><strong>C. 交叉验证</strong></li>
<li><strong>D. 自助法</strong></li>
</ul>
<p>14.对回归问题和分类问题的评价 <strong>最常用的指标都是准确率和召回率</strong>。<strong>错误</strong></p>
<p>15.<strong>输出变量为有限个离散变量的预测问题</strong>是回归问题；输出变量<strong>为连续变量的预测问题是</strong>分类问题。<strong>B.错误</strong></p>
<p>15.1分类和回归都可用于预测，<strong>分类的输出是离散的类别值</strong>，而回归的输出是是连续值。 <strong>A. 对</strong></p>
<p>16.<strong>朴素贝叶斯算法</strong>是基于贝叶斯定理与特征条件独立假设的<strong>分类方法</strong>。<strong>A.对的</strong></p>
<p>17.<u>模型选择方法</u>主要有(     <strong>AB</strong>       )。</p>
<ul>
<li><strong>A. 正则化（Regularization）</strong></li>
<li><strong>B. 交叉验证（Cross Validation）</strong></li>
</ul>
<p>18.<strong>分类</strong>是预测数据对象的<u>离散类别</u>，<strong>预测</strong>是用于数据对象的<u>连续取值</u>。<strong>A. 对</strong></p>
<p>19.在分类型机器学习过程中,下面有关分类算法的选择<strong>说法错误的</strong>是( AD)。</p>
<ul>
<li><strong>A. 算法参数是默认调好的,分析过程不需要修改</strong></li>
<li>B. 分类算法的优劣需要通过实验比较才能确定</li>
<li>C. 分类算法对数据有一定的要求,一种算法不能解决所有的分类问题</li>
<li><strong>D. 分类算法的结果只要训练样本准确度高就可以使用了</strong></li>
</ul>
<hr>
<h3 id="8-聚类"><a href="#8-聚类" class="headerlink" title="8.聚类"></a><strong>8.聚类</strong></h3><p>1.当不知道数据所带标签时，可以使用哪种技术<strong>促使带同类标签的数据与带其他标签的数据相分离</strong>？<strong>（聚类）</strong></p>
<p>2.如何衡量聚类质量，<strong>需要考虑数据点间的连通性</strong></p>
<p>3.哪种聚类方法可以提供聚类树形图，<strong>层次聚类</strong></p>
<p>4.通过以下哪些指标我们可以<u>在层次聚类中寻找两个集群之间的差异</u>？ABC</p>
<p><strong>A. 单链 B. 完全链接 C. 平均链接</strong></p>
<p>5.聚类分析中，<strong>簇间距离可以定义为</strong>（ ABCD）</p>
<ul>
<li><u>A. 最短距离法（最大相似度）</u></li>
<li><u>B. 最长距离法（最小相似度）</u></li>
<li><u>C. 类平均法</u></li>
<li><u>D. 中心法（两类的两个中心点的距离为簇间距离）</u></li>
</ul>
<p><u>6.聚类系数的外部指标是指将聚类结果</u>和某个“参考模型”进行比较。<strong>A. 对</strong></p>
<p>7.<em><strong>DBSCAN</strong></em>(Density-Based Spatial Clustering of Applications with Noise)</p>
<p><strong>DBSCAN是一个比较有代表性的基于密度的聚类算法。</strong></p>
<p>DBSCAN在最坏情况下的<u>时间复杂度是，**$O(m^2)$**</u></p>
<p><u>DBSCAN是相对抗噪声的，并且能够处理任意形状和大小的簇</u>。<strong>对的</strong></p>
<p>7.1 使用Python的sklearn.cluster库中的<strong>DBSCAN算法进行聚类的时候</strong>，<u>参数eps和min_samples的描述正确的是（ ）。</u></p>
<ul>
<li><p><strong>B. eps越小，聚出来的类越多</strong></p>
</li>
<li><p><strong>C. min_samples越小，一个簇中包含的样本点越少</strong></p>
</li>
</ul>
<p>8.<strong>基于密度的聚类算法代表算法</strong>有（  ABC  ） </p>
<p><strong>A. DBSCAN算法    B. OPTICS算法    C. DENCLUE算法</strong></p>
<p>9.Python中<strong>层次聚类的函数</strong>是AgglomerativeClustering，<u>重要的参数包含</u>（  ABC ）。 </p>
<p><strong>A. n_clusters    B. affinity    C. linkage</strong></p>
<p>9.1层次聚类的函数AgglomerativeClustering中，<strong>linkage是类间距离的定义</strong>，其取值包含（ ABC） </p>
<ul>
<li><strong>A. ward</strong></li>
<li><strong>B. average</strong></li>
<li><strong>C. complete</strong></li>
</ul>
<p>10.哪些数据特性都是对聚类分析具有很强影响的。(   ABCD   )</p>
<ul>
<li><strong>A. 高维性</strong></li>
<li><strong>B. 规模</strong></li>
<li><strong>C. 稀疏性</strong></li>
<li><strong>D. 噪声和离群点</strong></li>
</ul>
<p>11.<strong>聚类分析</strong>是一种有监督的学习方法。<strong>B.错的</strong></p>
<p>12.<strong>影响聚类结果的主要因素有哪些</strong>（ ABCD ） </p>
<ul>
<li><strong>A. 分类准则</strong></li>
<li><strong>B. 相似性测度（度量）</strong></li>
<li><strong>C. 特征量选择</strong></li>
<li><strong>D. 量纲</strong></li>
</ul>
<p>13.<strong>层次聚类可分为“自顶向下”和“自底向上”</strong>两种策略；<strong>A.对的</strong></p>
<p>14.下列哪项<strong>不属于聚类分析的算法</strong>(D)</p>
<ul>
<li>A. K-Means</li>
<li>B. K-中心点</li>
<li>C. 系统聚类</li>
<li><strong>D. Apriori算法</strong></li>
</ul>
<p>15.某电商分析人员希望通过聚类方法定位代商家刷信用级别的违规者，以下哪些操作不应该进行？  BD</p>
<ul>
<li><strong>B. 对变量进行百分位秩转换</strong> </li>
<li><strong>D. 对变量进行分箱处理</strong> </li>
</ul>
<hr>
<h3 id="9-回归模型"><a href="#9-回归模型" class="headerlink" title="9.回归模型"></a><strong>9.回归模型</strong></h3><p>1.有关回归模型的系数,以下<strong>说法错误的是</strong>哪个(  B )。</p>
<p>A. 一元线性回归模型的系数可以使用最小二乘法求得<br><strong>B. 多元回归模型的系数可以使用梯度下降法求得</strong><br>C. 一元线性回归模型的系数大小和正负说明自变量对因变量的相对影响大小<br>D. 回归分析的目的是计算回归方程的系数,使得样本的输入和输出变量之间的关系能够合理拟合</p>
<p>2.回归分析中按照自变量和因变量的关系类型可以分为？（ <strong>AB</strong> ） </p>
<ul>
<li><strong>A. 线性回归分析</strong></li>
<li><strong>B. 非线性回归分析</strong></li>
</ul>
<p>3.线性模型的优点包括？（  <strong>ABCD</strong> ） </p>
<ul>
<li><strong>A. 形式简单、易于建模</strong></li>
<li><strong>B. 可解释性</strong></li>
<li><strong>C. 引入层级结构或高维映射</strong></li>
<li><strong>D. 线性模型中系数直观表达了各属性在预测中的重要性</strong></li>
</ul>
<p>4.(单选题)<strong>线性判别分析</strong>是一种（ A）的方法。<strong>A.降维</strong></p>
<p>5.对于非线性回归问题,以下说法<strong>错误的</strong>是哪个(A )。</p>
<ul>
<li><strong>A. 可以分别求单个自变量与因变量的回归方程,然后简单求这些方程的加权和</strong></li>
<li>B. 非线性回归方程的系数需要把其转化为线性回归方程才方便求解</li>
<li>C. 非线性回归模型的检验也可以使用R2</li>
<li>D. Logistic回归是一种典型的广义线性回归模型</li>
</ul>
<hr>
<h3 id="10-支持向量机SVM"><a href="#10-支持向量机SVM" class="headerlink" title="10.支持向量机SVM"></a><strong>10.支持向量机SVM</strong></h3><p>1.<u>线性SVM和一般线性分类器的区别</u>主要是，<strong>是否确保间隔最大化</strong></p>
<p>2.在SVM领域中，margin的含义是，<strong>间隔</strong></p>
<p>3.为什么通常要选择margin最大的分类器， <strong>望获得较低的测试误差</strong></p>
<p><u>4.SVM本身是应用于二分类的</u>，若处理多分类必须进行改进。</p>
<p>若采用**”one vs all”<strong>解决5分类问题，</strong>需要设计（5）个分类器**。 </p>
<p>若采用**”one vs one”<strong>解决5分类问题</strong>，需要设计（10）个分类器。**</p>
<p>4.1<strong>选择Logistic回归</strong>中的<strong>One-Vs-All</strong>方法中的哪个选项是真实的。（n&gt;2）</p>
<ul>
<li><strong>A. 需要在n类分类问题中适合n个模型</strong></li>
</ul>
<p>5.假设超平面为w<em>x+b=0，其margin的大小为（ ）。*<em>2/|w|</em></em></p>
<p>6.<u>支持向量</u>（support vectors）指的是（ ）,<strong>决定分类面可以平移的范围的数据点</strong></p>
<p>7.<u>支持向量机SVM</u>是一种（    ）算法  <strong>小样本下的统计机器学习</strong></p>
<p>8.在SVM当中，主要的运算形式是（ ）。<strong>向量内积</strong></p>
<p>9.（  ）是定义在特征空间上的、间隔最大、<u>支持核技巧的分类器</u>。 <strong>SVM支持向量机</strong></p>
<p>10.对于SVM，<u>在映射后的高维空间直接进行计算的主要问题是</u>，<strong>计算复杂度高</strong></p>
<p>11.以下关于<u>SVM支持向量机</u>的说法正确的是 （  )。</p>
<ul>
<li><strong>C. SVM方法简单，鲁棒性较好</strong></li>
<li><strong>D. SVM分类面取决于支持向量</strong></li>
</ul>
<p>12.<u>支持向量机是一个分类器</u>，超平面上的数据是支持向量，超平面以外的数据可以辅助分类。<strong>错的</strong></p>
<hr>
<h3 id="11-K-Means-K均值算法"><a href="#11-K-Means-K均值算法" class="headerlink" title="11.K-Means(K均值算法)"></a><strong>11.K-Means(K均值算法)</strong></h3><p>1.为了在K均值算法中找到簇的最优值，可以使用 <strong>Elbow法</strong>，关注的就是方差百分比</p>
<p>2.K均值聚类时，<u>初始化不良会导致收敛速度差</u> <strong>A. 对</strong></p>
<p>3.<u>可以试着运行不同的质心初始化算法</u>，可以获得和全局最小值有关的K均值算法的良好结果。<strong>A. 对</strong></p>
<p>4.在对数据集执行K均值聚类分析以后，你得到了下面的树形图。从树形图中不能得出那些结论呢？（    ） </p>
<p><img src="https://p.ananas.chaoxing.com/star3/origin/688fdc316ba97d6a0ca155d7da81a06e.png" alt="img"> </p>
<ul>
<li>A. 在聚类分析中有28个数据点</li>
<li>B. 被分析的数据点里最佳聚类数是4</li>
<li>C. 使用的接近函数是平均链路聚类</li>
<li><strong>D. 对于上面树形图的解释不能用于K均值聚类分析</strong></li>
</ul>
<p>5.K-means算法的缺点有（  ABCD  ）</p>
<ul>
<li><strong>A. 只有当簇均值有定义的情况下，k均值方法才能使用。</strong></li>
<li><strong>B. 用户必须首先给定簇数目。</strong></li>
<li><strong>C. 不适合发现非凸形状的簇，或者大小差别很大的簇。</strong></li>
<li><strong>D. 对噪声和离群点数据敏感。</strong></li>
</ul>
<p>6.K-Means聚类算法可大致分为以下几个步骤，步骤中说法错误的是（ C）</p>
<ul>
<li>A. 任意选取两个点作为两个簇的初始中心；</li>
<li>B. 对剩余的每个对象，根据其与各个簇中心的距离，将它赋给最近的簇对；</li>
<li><strong>C. 继续使用上步获得的簇中心；</strong></li>
<li>D. 重新计算数据集中每个点到两个簇中心的距离，根据其值进行重新分配。</li>
</ul>
<p>7.<u>应用K均值算法之前，特征缩放是一个很重要的步骤</u>。这是为什么呢（  A   ） </p>
<ul>
<li><strong>A. 在距离计算中，它为所有特征赋予相同的权重。</strong></li>
</ul>
<hr>
<h2 id="二、填空计算题"><a href="#二、填空计算题" class="headerlink" title="二、填空计算题"></a>二、填空计算题</h2><h3 id="1-相似性计算"><a href="#1-相似性计算" class="headerlink" title="1.相似性计算"></a>1.相似性计算</h3><h4 id="1-二值离散型属性的相似性计算方法（计算样本间的距离）"><a href="#1-二值离散型属性的相似性计算方法（计算样本间的距离）" class="headerlink" title="(1) 二值离散型属性的相似性计算方法（计算样本间的距离）"></a>(1) 二值离散型属性的相似性计算方法（计算样本间的距离）</h4><ol>
<li><p>10维特征的二值离散型属性样本A,B分别为A=[1 0 0 0 0 0 0 0 0 0],B=[1 0 0 0 0 0 1 0 0 1],A,B 的相似性SMC = （     ）。JC=（       ）</p>
<p><strong>0.2，2/3</strong></p>
</li>
<li><p>10维特征的二值离散型属性样本A,B分别为A=[1 0 0 1 0 0 0 0 0 0],B=[1 0 0 0 0 0 1 0 0 1],A,B 的相似性SMC = （     ）。JC=（       ）</p>
<p><strong>0.3，0.75</strong></p>
</li>
</ol>
<p>总结，自己画矩阵图计算即可</p>
<img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230530205142358.png" alt="image-20230530205142358" style="zoom:50%;" />

<img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230530204529248.png" alt="image-20230530204529248" style="zoom:40%;" />

<p><strong>SMC</strong>，简单匹配系数，用于对<strong>对称的</strong>二值离散型属性的样本间距离的计算</p>
<img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230530204828716.png" alt="image-20230530204828716" style="zoom: 45%;" />

<p><strong>Jaccard</strong>系数，<strong>不对称的</strong>二值离散型属性的样本间的距离计算</p>
<hr>
<h4 id="2-多值离散型属性的相似性计算"><a href="#2-多值离散型属性的相似性计算" class="headerlink" title="(2) 多值离散型属性的相似性计算"></a>(2) 多值离散型属性的相似性计算</h4><p>已知样本如下。<strong>简单匹配法计算x1,x4的相似性</strong>。d(x1,x4)= (             )</p>
<p><img src="https://p.ananas.chaoxing.com/star3/origin/25250ad2a5a46d2d9b7957333f0cf52c.png" alt="img"></p>
<p>正确答案：<br>    (1) 1/3   看x1,x4这行，三个字段相同的值占(2/3) , 相似性为1-2/3==1/3</p>
<hr>
<h3 id="2-熵的计算"><a href="#2-熵的计算" class="headerlink" title="2.熵的计算"></a>2.熵的计算</h3><p>1.以下是目标变量在训练集上的 8 个实际值 [0,0,0,1,1,1,1,1]，<strong>目标变量的熵是？</strong>（   ） </p>
<p>A. -(5/8 log(5/8) + 3/8 log(3/8))</p>
<hr>
<h3 id="3-混淆矩阵的计算"><a href="#3-混淆矩阵的计算" class="headerlink" title="3.混淆矩阵的计算"></a>3.混淆矩阵的计算</h3><p><img src="https://p.ananas.chaoxing.com/star3/origin/bf1d46e5200ef467641431a7666f8aea.png" alt="img"></p>
<p>1.某分类器的混淆矩阵如上表，该分类器的<strong>误分率</strong>为 <strong>（FP+FN）主对角线</strong>,<strong>9%</strong></p>
<p>2.该分类器的<strong>查准率（Precision）</strong>为 ，<strong>P=TP/(TP+FP)<strong>，</strong>竖着看  30%</strong></p>
<p>3.该分类器的<strong>查全率</strong>（Recall）为，<strong>TP/(TP+FN) 查全率</strong>（召回率），<strong>横着看 60%</strong></p>
<hr>
<h3 id="4-K均值聚类方法"><a href="#4-K均值聚类方法" class="headerlink" title="4.K均值聚类方法"></a>4.K均值聚类方法</h3><p>1.假设你想用K均值聚类方法将7个观测值聚类到3个簇中，在第一次迭代簇之后，C1、C2、C3具有以下观测值： C1: {(2,2), (4,4), (6,6)} C2: {(0,4), (4,0)} C3: {(5,5), (9,9)} 在第二次迭代中，</p>
<p>01<strong>观测点（9，9）到集群质心C1的 Manhattan 距离是？A</strong></p>
<p><strong>C1:((2+4+6)/3, (2+4+6)/3)（4,4）和（9,9）的 Manhattan 距离是：（9-4）+（9-4）= 10。</strong></p>
<p>02如果继续进行第二次迭代，哪一个将成为集群的质心？A</p>
<ul>
<li><strong>A. C1: (4,4), C2: (2,2), C3: (7,7)</strong></li>
</ul>
<p>找到集群中数据点的质心 C1 = ((2+4+6)/3,(2+4+6)/3) = (4, 4)</p>
<p>找到集群中数据点的质心 C2 = ((0+4)/2, (4+0)/2) =(2, 2)</p>
<p>找到集群中数据点的质心 C3 = ((5+9)/2, (5+9)/2) =(7, 7)</p>
<p><strong>因此, C1: (4,4), C2: (2,2), C3: (7,7)</strong></p>
<hr>
<h3 id="5-分类器的正确率"><a href="#5-分类器的正确率" class="headerlink" title="5.分类器的正确率"></a>5.分类器的正确率</h3><p>1.设测试样本中，A类样本90个，B类样本10个。分类器C1将所有的测试样本都分成了A类。分类器C2将A类的90个样本分对了70个，将B类的样本分对了5个。C1的分类正确率为（　　），C2的分类正确率（    ）。（填写百分数形式，如：１０％）</p>
<p><strong>(1) ９０％    (2) ７５％</strong></p>
<p>C1的分类正确率为（　），正确的样本数/总样本数 —&gt;  90/100 == 90%</p>
<p>C2的分类正确率（    ）,  —&gt; (70+5)/100 == 75%</p>
<hr>
<h3 id="6-查准率、查全率计算"><a href="#6-查准率、查全率计算" class="headerlink" title="6.查准率、查全率计算"></a>6.查准率、查全率计算</h3><p>某局域网中有 A 类信息１４００条，B 类信息３００条，C 类信息３００条。科 技人员甲设计了搜索引擎，以搜索 A 类信息为目的，结果返回了 A 类信息７００条，B 类信 息２００条，C 类信息１００条。问该引擎的查准率为（ ），查全率为（ ）。 （填写百分数形式，如：１０％）</p>
<p><strong>70%，50%</strong></p>
<img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230528175516024.png" alt="image-20230528175516024" style="zoom:50%;" />

<p>该搜索引擎的**查准率 (竖着看)**为：70%（计算公式：查准率 = 检索到的相关信息数 / 检索到的全部信息数 × 100% = 700 / (700 + 200 + 100) × 100% = 70%）</p>
<p>该搜索引擎的**查全率 (横着看)**为：50%（计算公式：查全率 = 检索到的相关信息数 / 相关信息的总数 × 100% = 700 / 1400 × 100% = 50%）</p>
<hr>
<h2 id="三、重点大题"><a href="#三、重点大题" class="headerlink" title="三、重点大题"></a>三、重点大题</h2><h3 id="1-混淆矩阵"><a href="#1-混淆矩阵" class="headerlink" title="1.混淆矩阵"></a>1.混淆矩阵</h3><p><strong>题目</strong>：有20个样本，<strong>其中真实正例有10个，用p表示，负例有10个，用n表示</strong>。</p>
<p>Inst# 代表样本编号，Class代表样本真实的类别，Score表示利用模型得出每个测试样本<u>属于真实样</u></p>
<p><u>本的概率</u>。依次将Score概率从大到小排序，得到下表：</p>
<p><img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230528174013113.png" alt="image-20230528174013113"></p>
<h4 id="问题1"><a href="#问题1" class="headerlink" title="问题1"></a>问题1</h4><p><u>1.画出Score阈值为0.5时的混淆矩阵，计算此时的F1度量值。</u></p>
<p><strong>分析：</strong></p>
<p>（1）Score阈值为0.5时的混淆矩阵</p>
<p><strong>在左侧：分类器预测为正的情况， 相反右侧是分类器预测为负的情况</strong>，具体值在图中数即可</p>
<p>要知道混淆矩阵如何写，各个值对应的含义</p>
<p>TP: 分类器预测为正，真实为正</p>
<p>FP: 分类器预测为正，真实为负</p>
<p>FN:分类器预测为负，真实为正</p>
<p>TN:分类器预测为负，真实为负</p>
<img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230528174335722.png" alt="image-20230528174335722" style="zoom: 80%;" />

<hr>
<p>（2）<strong>F1度量值</strong>，F1是准确率和召回率的调和平均。</p>
<p>具体推导，</p>
<img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230528175516024.png" alt="image-20230528175516024" style="zoom:50%;" />

<p>计算F1记住公式即可，</p>
<img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230528180320715.png" alt="image-20230528180320715" style="zoom: 25%;" />

<p>  计算， </p>
<img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230528180217478.png" alt="image-20230528180217478" style="zoom:60%;" />

<p><strong>拓展：</strong></p>
<p>1的另一种出题方式，<u>不给出具体概率的情况。</u></p>
<p>现有20个样本，包括10个正例（横着看，真实正例：TP+FN），10个负例。<strong>当阈值为0.5时，分类器预测正例为10只，其中将4个反例预测为正例。</strong></p>
<p>试求出该分类结果的混淆矩阵和F1值。</p>
<p>分析：</p>
<p><u>其中将4个反例预测为正例</u>：（由一个值推出其他三个值）</p>
<p>预测器为正，真实为负，及FP=4 —-&gt; 其他值</p>
<p>共有20个样本：TP+FP+TN+FN=20;</p>
<p>10个正例：TP+FN=10； 10个反例：FP+TN=10；</p>
<p>预测正例为10：TP+FP=10；预测反例为10：FN+TN=10；</p>
<p>4个反例预测为正例：FP=4</p>
<hr>
<h4 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h4><p><u>2.画出ROC 曲线。</u></p>
<img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230528181537402.png" alt="image-20230528181537402" style="zoom:80%;" />

<p>补充：</p>
<img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230528181828459.png" alt="image-20230528181828459" style="zoom: 67%;" />

<p><strong>FP:预测为正，真实为负的数量，  TP:预测为正，真实为正的数量</strong></p>
<p>ROC 曲线的横坐标为FPR，纵坐标为TPR。</p>
<p>FPR是错误预测为正确的概率**(假正率)<strong>，TPR是正确预测为正确的概率</strong>(真正率)**。 每个点坐标（FPR, TPR）</p>
<hr>
<p>0.9&lt;阈值&lt;=1时，没有样本被预测为正例，所有样本被预测为反例。所以FP=0，TP=0，得ROC坐标**(0,0)**。</p>
<p>0.8&lt;阈值&lt;=9时，样本1预测为正例，其他样本被预测为反例。其中，样本1为真实正例，所以FP=0，TP=1，得ROC坐标(0,0),**(0,0.1)**。</p>
<p>0.7&lt;阈值&lt;=8时，样本1-2预测为正例。其中，样本1,2为真实正例，所以FP=0，TP=2，得ROC坐标(0,0),(0,0.1),(0,0.2)。</p>
<p>0.6&lt;阈值&lt;=7时，样本1-3预测为正例。其中，样本1,2为真实正例，样本3为真实反例，所以FP=1，TP=2，得ROC坐标(0,0),(0,0.1),(0,0.2),**(0.1,0.2)**。</p>
<p>0.55&lt;阈值&lt;=0.6时，样本1-4预测为正例。其中，样本1,2,4为真实正例，样本3为真实反例，所以FP=1，TP=3，得ROC坐标(0,0),(0,0.1),(0,0.2),(0.1,0.2),**(0.1,0.3)**。</p>
<p>……</p>
<p>具体计算图如下：</p>
<p><img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230528182846063.png" alt="image-20230528182846063"></p>
<p>结果：</p>
<p>ROC 曲线的<strong>横坐标为FPR，纵坐标为TPR</strong>。FPR是错误预测为正确的概率，TPR是正确预测为正确的概率。</p>
<p><img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230528183035478.png" alt="image-20230528183035478"></p>
<hr>
<h3 id="2-决策树"><a href="#2-决策树" class="headerlink" title="2.决策树"></a>2.决策树</h3><p>（使用信息增益的方法）</p>
<p><strong>题目：</strong></p>
<p>使用信息增益方法，计算下表中的决策树</p>
<p><img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230528183238910.png" alt="image-20230528183238910"></p>
<p>根据类别（是否）这一列来计算，</p>
<p><img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230528183445889.png" alt="image-20230528183445889"></p>
<p><img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230528183533928.png" alt="image-20230528183533928"></p>
<p><strong>考试推荐写法</strong></p>
<p><img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230528183635323.png" alt="image-20230528183635323"></p>
<p>其他特征信息增益，</p>
<img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230528183811110.png" alt="image-20230528183811110" style="zoom: 80%;" />

<p>利用上述结果，由于特征A3（<strong>房子特征</strong>）的信息增益最大，<strong>所以选择特征A3作为根节点的特征</strong>。它将训练数据集D划分为<strong>两个子集D1（A3取值为“是”）</strong>和<strong>D2（A3取值为“否”）</strong>。</p>
<p><u>“房子特征=是”的样本都对应“类别=是”，达到终止条件</u>，只用计算D2这个分支即可</p>
<p>然后对D2从特征A1（年龄），特征A2（工作），特征A4（信贷情况）中选择新的特征，计算各个特征信息增益。</p>
<p><img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230528184644145.png" alt="image-20230528184644145"></p>
<p><img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230528184913760.png" alt="image-20230528184913760"></p>
<p>利用上述结果，<strong>由于特征A2（工作特征）的信息增益最大</strong>，所以选择特征A2作为否分支的根节点。它将训练数据集D2划分为<strong>两个子集D21（A2取值为“是”）和D22（A2取值为“否”）</strong>。<u>且每个分支都只有一种结果，所以决策树划分完毕。</u></p>
<p> 可以画出决策树，</p>
<p><img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230528185023821.png" alt="image-20230528185023821"></p>
<hr>
<h3 id="3-核函数"><a href="#3-核函数" class="headerlink" title="3.核函数"></a>3.核函数</h3><p><strong>题目：</strong></p>
<p><img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230528185158910.png" alt="image-20230528185158910"></p>
<p>带公式计算即可，</p>
<p><img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230528185223704.png"></p>
<hr>
<h3 id="4-SVM"><a href="#4-SVM" class="headerlink" title="4.SVM"></a>4.SVM</h3><p>支持向量机（SVM）的主要思想是<u>建立一个超平面作为决策曲面，使得正例和反例之间的隔离边缘被最大化。更精确说，支持向量机是结构风险最小化方法的近似实现。</u></p>
<p>题目：</p>
<p>带公式计算,</p>
<p><img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/image-20230528185526468.png" alt="image-20230528185526468"></p>
<hr>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>练习题整理自学习通的练习题，及桂电的&lt;&lt;机器学习&gt;&gt;课程答疑资料。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://ariesfun.gitee.io">Ariesfun</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://ariesfun.gitee.io/posts/b9aa.html">https://ariesfun.gitee.io/posts/b9aa.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://ariesfun.gitee.io" target="_blank">AriesfunのBlog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/">学习记录</a><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">机器学习与数据挖掘</a></div><div class="post_share"><div class="social-share" data-image="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/202306040216162.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/43cd.html"><img class="prev-cover" src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/202303051640434.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Linux基础 第五讲 Git</div></div></a></div><div class="next-post pull-right"><a href="/posts/5544.html"><img class="next-cover" src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/202306040105742.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">23生产实习 大数据开发实训笔记合集 更新中...</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/21e5.html" title="C++ 设计模式(单例+工厂)"><img class="cover" src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/202308090027619.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-09</div><div class="title">C++ 设计模式(单例+工厂)</div></div></a></div><div><a href="/posts/6d6b.html" title="C&#x2F;C++ 内存四区总结"><img class="cover" src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/202308090026441.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-09</div><div class="title">C&#x2F;C++ 内存四区总结</div></div></a></div><div><a href="/posts/5544.html" title="23生产实习 大数据开发实训笔记合集 更新中..."><img class="cover" src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/202306040105742.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-06-04</div><div class="title">23生产实习 大数据开发实训笔记合集 更新中...</div></div></a></div><div><a href="/posts/34c8.html" title="23生产实习 Day04(06&#x2F;01) HDFS的API及字符统计案例 (CharCount)"><img class="cover" src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/202306040105742.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-06-04</div><div class="title">23生产实习 Day04(06&#x2F;01) HDFS的API及字符统计案例 (CharCount)</div></div></a></div><div><a href="/posts/dd24.html" title="23生产实习 Day03(05&#x2F;31) Zookeeper的安装方式"><img class="cover" src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/202306040105742.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-06-04</div><div class="title">23生产实习 Day03(05&#x2F;31) Zookeeper的安装方式</div></div></a></div><div><a href="/posts/3d5e.html" title="23生产实习 Day02(05&#x2F;30) Hadoop核心技术"><img class="cover" src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/202306040105742.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-06-04</div><div class="title">23生产实习 Day02(05&#x2F;30) Hadoop核心技术</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/logo_22.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Ariesfun</div><div class="author-info__description">这里有互联网技术分享、计算机专业知识学习和生活日志...</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">48</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">32</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">17</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/ariesfun"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="http://wpa.qq.com/msgrd?v=3&amp;uin=2018351840&amp;site=qq&amp;menu=yes" target="_blank" title="QQ"><i class="fab fa-qq"></i></a><a class="social-icon" href="https://space.bilibili.com/172382106" target="_blank" title="Bilibili"><i class="fab fa-bilibili"></i></a><a class="social-icon" href="mailto:ariesfun2019@outlook.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://github.com/ariesfun" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">一些资源共享: (仅限校友内网访问)
http://10.200.21.35:8100/s/WJhg
</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98-%E5%88%B7%E9%A2%98%E7%BB%83%E4%B9%A0-%E5%A4%8D%E4%B9%A0%E7%89%88"><span class="toc-text">机器学习与数据挖掘 刷题练习(复习版)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E5%8D%95%E9%80%89%E9%A2%98%E5%8F%8A%E5%88%A4%E6%96%AD"><span class="toc-text">一、单选题及判断</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%95%B0%E6%8D%AE"><span class="toc-text">1.数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93"><span class="toc-text">2.数据仓库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95"><span class="toc-text">3.机器学习方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E8%A3%85%E8%A2%8B"><span class="toc-text">4.装袋</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-text">5.决策树</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="toc-text">6.随机森林</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-%E5%88%86%E7%B1%BB"><span class="toc-text">7.分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-%E8%81%9A%E7%B1%BB"><span class="toc-text">8.聚类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="toc-text">9.回归模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BASVM"><span class="toc-text">10.支持向量机SVM</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-K-Means-K%E5%9D%87%E5%80%BC%E7%AE%97%E6%B3%95"><span class="toc-text">11.K-Means(K均值算法)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%A1%AB%E7%A9%BA%E8%AE%A1%E7%AE%97%E9%A2%98"><span class="toc-text">二、填空计算题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E7%9B%B8%E4%BC%BC%E6%80%A7%E8%AE%A1%E7%AE%97"><span class="toc-text">1.相似性计算</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E4%BA%8C%E5%80%BC%E7%A6%BB%E6%95%A3%E5%9E%8B%E5%B1%9E%E6%80%A7%E7%9A%84%E7%9B%B8%E4%BC%BC%E6%80%A7%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%EF%BC%88%E8%AE%A1%E7%AE%97%E6%A0%B7%E6%9C%AC%E9%97%B4%E7%9A%84%E8%B7%9D%E7%A6%BB%EF%BC%89"><span class="toc-text">(1) 二值离散型属性的相似性计算方法（计算样本间的距离）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E5%A4%9A%E5%80%BC%E7%A6%BB%E6%95%A3%E5%9E%8B%E5%B1%9E%E6%80%A7%E7%9A%84%E7%9B%B8%E4%BC%BC%E6%80%A7%E8%AE%A1%E7%AE%97"><span class="toc-text">(2) 多值离散型属性的相似性计算</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E7%86%B5%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="toc-text">2.熵的计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="toc-text">3.混淆矩阵的计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-K%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95"><span class="toc-text">4.K均值聚类方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E5%88%86%E7%B1%BB%E5%99%A8%E7%9A%84%E6%AD%A3%E7%A1%AE%E7%8E%87"><span class="toc-text">5.分类器的正确率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E6%9F%A5%E5%87%86%E7%8E%87%E3%80%81%E6%9F%A5%E5%85%A8%E7%8E%87%E8%AE%A1%E7%AE%97"><span class="toc-text">6.查准率、查全率计算</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E9%87%8D%E7%82%B9%E5%A4%A7%E9%A2%98"><span class="toc-text">三、重点大题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5"><span class="toc-text">1.混淆矩阵</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%981"><span class="toc-text">问题1</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%982"><span class="toc-text">问题2</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-text">2.决策树</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%A0%B8%E5%87%BD%E6%95%B0"><span class="toc-text">3.核函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-SVM"><span class="toc-text">4.SVM</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-text">参考资料</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/21e5.html" title="C++ 设计模式(单例+工厂)"><img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/202308090027619.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="C++ 设计模式(单例+工厂)"/></a><div class="content"><a class="title" href="/posts/21e5.html" title="C++ 设计模式(单例+工厂)">C++ 设计模式(单例+工厂)</a><time datetime="2023-08-08T16:29:53.011Z" title="发表于 2023-08-09 00:29:53">2023-08-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/6d6b.html" title="C/C++ 内存四区总结"><img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/202308090026441.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="C/C++ 内存四区总结"/></a><div class="content"><a class="title" href="/posts/6d6b.html" title="C/C++ 内存四区总结">C/C++ 内存四区总结</a><time datetime="2023-08-08T16:29:53.008Z" title="发表于 2023-08-09 00:29:53">2023-08-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/7d34.html" title="LeetCode Hot100 分类刷题汇总"><img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/202307250329115.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="LeetCode Hot100 分类刷题汇总"/></a><div class="content"><a class="title" href="/posts/7d34.html" title="LeetCode Hot100 分类刷题汇总">LeetCode Hot100 分类刷题汇总</a><time datetime="2023-07-24T19:29:53.728Z" title="发表于 2023-07-25 03:29:53">2023-07-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/8b7.html" title="C++ 算法刷题 - 常用技巧汇总"><img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/202307210218346.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="C++ 算法刷题 - 常用技巧汇总"/></a><div class="content"><a class="title" href="/posts/8b7.html" title="C++ 算法刷题 - 常用技巧汇总">C++ 算法刷题 - 常用技巧汇总</a><time datetime="2023-07-20T17:36:58.938Z" title="发表于 2023-07-21 01:36:58">2023-07-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/8b87.html" title="C++ 常用STL及用法 - 速查文档"><img src="https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/202307210133034.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="C++ 常用STL及用法 - 速查文档"/></a><div class="content"><a class="title" href="/posts/8b87.html" title="C++ 常用STL及用法 - 速查文档">C++ 常用STL及用法 - 速查文档</a><time datetime="2023-07-20T17:36:58.935Z" title="发表于 2023-07-21 01:36:58">2023-07-21</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://imgbed-funblog.oss-cn-chengdu.aliyuncs.com/img/202306040216162.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By Ariesfun</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo-teal-two.vercel.app',
      region: '',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo-teal-two.vercel.app',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      countELement.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runFn)
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script src="/js/weather.js"></script> <script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>